{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECONSTRUCTNIG NOISY IMAGES USING DENOISING AUTOENCODER\n",
    "\n",
    "_**Building a denoising stacked autoencoder to reconstruct noisy images.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the Fashion dataset into train and test set. This is a dataset of 60,000 28x28 grayscale\n",
    "# images of 10 fashion categories, along with a test set of 10,000 images\n",
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatype of train set over `dtype` property to normalize the input accordingly\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows some of the fashion items as random samples\n",
    "\n",
    "ROWS = 5\n",
    "COLUMNS = 9\n",
    "\n",
    "fig,ax = plt.subplots(ROWS, COLUMNS, figsize = (10,5))     # Figure to contain subplots in 5-rows and 9-columns arrangement\n",
    "ax = ax.ravel()                                 # Flattens the axes allowing accessing each axis contiguously\n",
    "for i in range(ROWS * COLUMNS):\n",
    "  rand = np.random.randint(0, len(X_train_full)) # Generate an index randomly to be used for random item selection\n",
    "  image = X_train_full[rand]                    # Gets an image indexed by the random number generated in previous step\n",
    "  ax[i].imshow(image, cmap = 'binary')          # Shows the image\n",
    "  ax[i].set_title(y_train_full[rand])           # Sets the class of the image as title to be shown in the figure\n",
    "  ax[i].axis(\"off\")                             # Set the axis off for being non-relevant in this case\n",
    "\n",
    "fig.suptitle(\"Fashion Items\")                   # Sets title of the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the datatype found earlier, normalise the values in the range 0 â€” 1\n",
    "\n",
    "X_train_full = # ...\n",
    "X_test = # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train set further to separate 10000 samples as validation set from full train set stratifically\n",
    "# by calling method `train_test_split` and passing full train set with labels seperated by comma in\n",
    "# the first two parameters, then pass 10000 in `test_size` and label `y_train_full` in `stratify` parameter.\n",
    "# Additionally, an integer can also be passed in parameter.\n",
    "\n",
    "X_train, X_val, y_train, y_val = # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Denoising Stacked Autoencoder using Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)      # Sets the global random seed for operations that rely on a random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an encoder of the stacked encoder using sequential model by calling method\n",
    "# `tf.keras.Sequential` and passing a list of the following layers. Layer\n",
    "# `tf.keras.layers.Flatten()` to flatten 2D images into 1D, then \n",
    "# `tf.keras.layers.Dropout` layer with 0.5 as parameter argument to \n",
    "# indicate 50% droput to simulate noise in the input images, then\n",
    "# a `tf.keras.layers.Dense` layer with 100 output units and \"relu\" as `activation`,\n",
    "# and lastly another `tf.keras.layers.Dense` layer with 30 output units and \"relu\" as `activation`\n",
    "\n",
    "dropout_encoder = # Write code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, create a mirrored decoder for the autoencoder using sequential model by calling\n",
    "# method `tf.keras.Sequential` and passing a list of the following layers. Layer\n",
    "# `tf.keras.layers.Dense` layer with `100` output units and \"relu\" as `activation`, then\n",
    "# `tf.keras.layers.Dense` layer with output units equal to the total number of pixels\n",
    "# in the input image and without any activation, and lastly a `tf.keras.layers.Reshape`\n",
    "# layer with list of two values representing the shape of the input images to convert\n",
    "# 1D output back to 2D as original image dimension\n",
    "\n",
    "dropout_decoder = # Write code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an autoencoder combining both encoder and decoder by calling \n",
    "# `tf.keras.Sequential` method and passing a list containing instances of the \n",
    "# encoder and decoder created in the previous steps.\n",
    "dropout_autoencoder = # ...\n",
    "\n",
    "# Compile the model by calling `compile` method of the autoencoder instance\n",
    "# and passing \"mse\" to `loss` and \"nadam\" to `optimizer` parameter.\n",
    "# Setting metrics are optional as optimization will be based on loss function provided\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the autoencoder by calling `fit` method of the autoencoder instance and\n",
    "# passing same train set as first two parameter arguments (considering features and \n",
    "# target will be same for the autoencoder), then a tuple containing same validation\n",
    "# set as two elements and pass it to parameter `validation_data`, then 100 \n",
    "# to `epochs`, and lastly a list containing an early stopping instance in\n",
    "# parameter `callbacks`. Create an instance of early stopping by calling\n",
    "# `tf.keras.callbacks.EarlyStopping` passing into \"val_loss\" in its `monitor`\n",
    "# parameter, 10 to `patience` and `True` to its `restore_best_weights` parameter.\n",
    "\n",
    "history = #Write code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing learning curve\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")        # Plots training loss\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")  # Plots validation loss\n",
    "plt.xlabel(\"Epochs\")                                            # Sets label for x-axis\n",
    "plt.ylabel(\"Loss (MSE)\")                                        # Sets label for y-axis\n",
    "plt.legend()                                                    # Enables legends to be shown\n",
    "plt.title(\"Learning Curve\")                                     # Sets the title of the plot\n",
    "\n",
    "plt.show()                                                      # Finally, shows the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Performance of Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random noise to all the images in the test set first by creating \n",
    "# a instance of dropout layer calling `tf.keras.layers.Dropout` with 0.5\n",
    "# as its parameter value. Then call the dropout layer as a function passing\n",
    "# test set as first parameter value and `True` to its `training` parameter.\n",
    "\n",
    "# ...\n",
    "X_test_noisy = # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, reconstructs noisy images created in the previous step by calling \n",
    "# autoencoder instance as function and passing the noisy test set as its parameter\n",
    "reconstructed_test_images = # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows few of randomly selected reconstructed images\n",
    "\n",
    "fig,ax = plt.subplots(5,10,figsize = (10,5))\n",
    "\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i in range(25):\n",
    "    rand = np.random.randint(0,len(X_test))\n",
    "    noisy_image = X_test_noisy[rand]\n",
    "    reconstructed_image = reconstructed_test_images[rand]\n",
    "\n",
    "    ax[i*2].imshow(noisy_image, cmap = 'binary')\n",
    "    ax[i*2].axis(\"off\")\n",
    "    \n",
    "    ax[i*2 + 1].imshow(reconstructed_image, cmap = 'binary')\n",
    "    ax[i*2 + 1].axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Sie-by-Side Visual Comparison between Noisy and Reconstructed Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "- Why was the dropout layer used in the encoder? Analyze its working in this experiment.\n",
    "\n",
    "- What is visual structure of the autoencoder created in this experiment? How does the structure affect the working of the autoencoder?\n",
    "\n",
    "- How was the autoencoder compiled and trained?\n",
    "\n",
    "- How was the trained autoencoder tested over the train set?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
