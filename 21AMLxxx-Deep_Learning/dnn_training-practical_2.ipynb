{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e458d0-eeb7-47fc-8397-2b4133d9db6f",
   "metadata": {},
   "source": [
    "# Training Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc129ebe-d7ab-44d6-9ada-1c03f6d15113",
   "metadata": {},
   "source": [
    "## Practical 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b66544-447e-4368-9d19-1b9fd6528772",
   "metadata": {},
   "source": [
    "_**Experiment on Fashion MNIST or any other appropriate dataset to check if reusing pretrained layers in transfer learning makes the training possible with less data and saves training time. Also check for any model performance improvement.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231683f2-d3b4-457f-b392-a01108994cb3",
   "metadata": {},
   "source": [
    "First a model will be trained on set A (for classification task with 8 classes such as trousers, dresses, coats, sandals, shirts, sneakers, bags, and ankle boots in Fashion MNIST dataset). Then the learning will be reused for another a binary classification task on set B (the remaining 2 classes such as T-shirts/tops and pullovers in the saame dataset) since classes in set A are somewhat similar to classes in set B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53479574-53f9-4e32-b96a-9ade44a7e4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports required packages\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d1bacd1-7c13-4076-8a24-b637379fe448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loads fashion mnist dataset\n",
    "fashion = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a5a6b03-2bcd-4dfa-8845-36f7848446dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Considering dataset is organized in tuple, items are referenced as follows\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb904468-8537-407c-ac8a-7b7310bef2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (60000, 28, 28) \n",
      "Test dataset shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Checks the shape of the datasets\n",
    "print(\"Train dataset shape:\", X_train_full.shape,\n",
    "      \"\\nTest dataset shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "908dfc4a-d5f4-4d52-9f68-76f4641ed489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splits train dataset further to seperate 5000 instances to be used as validation set\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=5000, random_state=42, stratify=y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889aa6a0-b345-441a-b46d-d2a5a3278893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each training and test example is assigned to one of the following labels.\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \\\n",
    "               \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb12e04-a37e-4713-8aba-420da4b94609",
   "metadata": {},
   "source": [
    "**Splits Fashion MNIST into tasks A and B, then train and save.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "198021a2-314f-42e3-b75e-87e756186cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_class_id = class_names.index(\"Pullover\")\n",
    "neg_class_id = class_names.index(\"T-shirt/top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f00fff-4181-4135-b4c7-913a9f93a506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
    "    y_A = y[~y_for_B]\n",
    "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
    "    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
    "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
    "        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A\n",
    "    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5461b2bd-2b28-4c93-98af-057b105b6f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_val_A, y_val_A), (X_val_B, y_val_B) = split_dataset(X_val, y_val)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2903a952-c1c1-4f78-9938-1badf74ca16e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 09:31:08.660696: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_A = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abc9d6bf-32da-4671-9e46-bdcb327e0867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 10s 7ms/step - loss: 5.6492 - accuracy: 0.4103 - val_loss: 1.2615 - val_accuracy: 0.5045\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 1.1841 - accuracy: 0.5474 - val_loss: 1.0626 - val_accuracy: 0.5690\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 1.0337 - accuracy: 0.5819 - val_loss: 0.9390 - val_accuracy: 0.5913\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.8505 - accuracy: 0.6569 - val_loss: 0.7599 - val_accuracy: 0.7048\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 10s 7ms/step - loss: 0.7295 - accuracy: 0.7153 - val_loss: 0.6834 - val_accuracy: 0.7232\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 9s 6ms/step - loss: 0.6672 - accuracy: 0.7342 - val_loss: 0.6690 - val_accuracy: 0.7305\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 14s 10ms/step - loss: 0.6254 - accuracy: 0.7438 - val_loss: 0.6013 - val_accuracy: 0.7350\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 7s 5ms/step - loss: 0.5909 - accuracy: 0.7525 - val_loss: 0.5776 - val_accuracy: 0.7410\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 7s 5ms/step - loss: 0.5603 - accuracy: 0.7618 - val_loss: 0.5594 - val_accuracy: 0.7793\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.5460 - accuracy: 0.7656 - val_loss: 0.5373 - val_accuracy: 0.7513\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.5248 - accuracy: 0.7735 - val_loss: 0.5507 - val_accuracy: 0.7688\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 7s 5ms/step - loss: 0.5027 - accuracy: 0.7810 - val_loss: 0.5175 - val_accuracy: 0.7905\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 10s 7ms/step - loss: 0.4863 - accuracy: 0.7879 - val_loss: 0.5068 - val_accuracy: 0.7768\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.4674 - accuracy: 0.7990 - val_loss: 0.4725 - val_accuracy: 0.7995\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 7s 5ms/step - loss: 0.4498 - accuracy: 0.8044 - val_loss: 0.4405 - val_accuracy: 0.8108\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 9s 7ms/step - loss: 0.4319 - accuracy: 0.8100 - val_loss: 0.4586 - val_accuracy: 0.8045\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.4231 - accuracy: 0.8113 - val_loss: 0.4308 - val_accuracy: 0.8092\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.4107 - accuracy: 0.8147 - val_loss: 0.4308 - val_accuracy: 0.8180\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 12s 9ms/step - loss: 0.4077 - accuracy: 0.8164 - val_loss: 0.4155 - val_accuracy: 0.8155\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 9s 7ms/step - loss: 0.4015 - accuracy: 0.8186 - val_loss: 0.4250 - val_accuracy: 0.8150\n"
     ]
    }
   ],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=20, validation_data=(X_val_A, y_val_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4ab4e83-f36a-4101-b3fd-f7bd07877147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./my_fashion_mnist_model_A/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./my_fashion_mnist_model_A/assets\n"
     ]
    }
   ],
   "source": [
    "model_A.save(\"./models/my_fashion_mnist_model_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07111be1-06f8-4eb1-b842-8af9c808dabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c45b8c0-8afa-4cfb-985d-cb66f1052e89",
   "metadata": {},
   "source": [
    "Now, to realize whether if transfer learning works or not, first train model B, then evaluate it, without reusing model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1630dfd8-83f4-419a-bacc-5fa82f952be4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 47ms/step - loss: 241.5345 - accuracy: 0.5050 - val_loss: 13.2833 - val_accuracy: 0.5050\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 6.2211 - accuracy: 0.6350 - val_loss: 0.5385 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.3296 - accuracy: 0.9300 - val_loss: 0.4761 - val_accuracy: 0.9040\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2511 - accuracy: 0.9200 - val_loss: 0.4628 - val_accuracy: 0.9200\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1944 - accuracy: 0.9250 - val_loss: 0.3994 - val_accuracy: 0.9200\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 50ms/step - loss: 0.1350 - accuracy: 0.9350 - val_loss: 0.3874 - val_accuracy: 0.9200\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.1296 - accuracy: 0.9450 - val_loss: 0.3898 - val_accuracy: 0.9180\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.1083 - accuracy: 0.9500 - val_loss: 0.3752 - val_accuracy: 0.9190\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.1062 - accuracy: 0.9350 - val_loss: 0.3770 - val_accuracy: 0.9100\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.1059 - accuracy: 0.9450 - val_loss: 0.4228 - val_accuracy: 0.9190\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.1235 - accuracy: 0.9450 - val_loss: 0.3950 - val_accuracy: 0.9140\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1062 - accuracy: 0.9650 - val_loss: 0.3791 - val_accuracy: 0.9150\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0932 - accuracy: 0.9550 - val_loss: 0.3651 - val_accuracy: 0.9050\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0892 - accuracy: 0.9550 - val_loss: 0.3779 - val_accuracy: 0.8450\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.1159 - accuracy: 0.9250 - val_loss: 0.3933 - val_accuracy: 0.9190\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0860 - accuracy: 0.9800 - val_loss: 0.3662 - val_accuracy: 0.9140\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.0684 - accuracy: 0.9650 - val_loss: 0.4342 - val_accuracy: 0.9260\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.1172 - accuracy: 0.9700 - val_loss: 0.3935 - val_accuracy: 0.9200\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0703 - accuracy: 0.9800 - val_loss: 0.3672 - val_accuracy: 0.9210\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0586 - accuracy: 0.9750 - val_loss: 0.3457 - val_accuracy: 0.9180\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_B = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B.fit(X_train_B, y_train_B, epochs=20, validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93c680e5-e1e4-4b3a-b622-19ae359de421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36726489663124084, 0.9179999828338623]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a102c1-7989-4cdf-9d72-cd09b9c89493",
   "metadata": {},
   "source": [
    "Model B reaches 91.79% accuracy on the test set. Now let's try reusing the pretrained model A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9d79bd98-5b33-4444-8057-b7a18f316032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_A = tf.keras.models.load_model(\"my_fashion_mnist_model_A\")\n",
    "\n",
    "model_B_on_A = tf.keras.Sequential(model_A.layers[:-1])\n",
    "\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61577729-0c7e-45db-8279-b4907bc3d3d4",
   "metadata": {},
   "source": [
    "As model_B_on_A and model_A actually share layers now, training one will update both models. To avoid that model_B_on_A should be built on top of a clone of model_A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be0f8c02-de3b-4fd8-9524-49201c8f80dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_A_clone = tf.keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d886bf8-57dc-4b99-b070-a0aa559a9273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates model_B_on_A just like in the previous cell\n",
    "\n",
    "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])\n",
    "\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b51bbea-ef3c-407a-9ad7-08be854768a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f75bb9df-22ff-46cd-92fc-ba71f9c2b586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 52ms/step - loss: 0.6611 - accuracy: 0.6550 - val_loss: 0.6802 - val_accuracy: 0.6200\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.6602 - accuracy: 0.6550 - val_loss: 0.6796 - val_accuracy: 0.6200\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.6593 - accuracy: 0.6550 - val_loss: 0.6789 - val_accuracy: 0.6200\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 0.6582 - accuracy: 0.6550 - val_loss: 0.6784 - val_accuracy: 0.6200\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df1e2d84-f381-4eb2-b4cb-c080940f4e28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.6513 - accuracy: 0.6650 - val_loss: 0.6738 - val_accuracy: 0.6730\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.6319 - accuracy: 0.7200 - val_loss: 0.6642 - val_accuracy: 0.6050\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6326 - accuracy: 0.6650 - val_loss: 0.6539 - val_accuracy: 0.6500\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.5895 - accuracy: 0.7100 - val_loss: 0.6334 - val_accuracy: 0.7010\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 0.5804 - accuracy: 0.7400 - val_loss: 0.6173 - val_accuracy: 0.7160\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5460 - accuracy: 0.7900 - val_loss: 0.5787 - val_accuracy: 0.7940\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.5392 - accuracy: 0.8000 - val_loss: 0.5947 - val_accuracy: 0.7130\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.5217 - accuracy: 0.8200 - val_loss: 0.5357 - val_accuracy: 0.8690\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4952 - accuracy: 0.8350 - val_loss: 0.5261 - val_accuracy: 0.8490\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4918 - accuracy: 0.8350 - val_loss: 0.5132 - val_accuracy: 0.8550\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4718 - accuracy: 0.8850 - val_loss: 0.5181 - val_accuracy: 0.8140\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4771 - accuracy: 0.8550 - val_loss: 0.5200 - val_accuracy: 0.8110\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4697 - accuracy: 0.8600 - val_loss: 0.4850 - val_accuracy: 0.8760\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4374 - accuracy: 0.9000 - val_loss: 0.4769 - val_accuracy: 0.9050\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.4231 - accuracy: 0.9100 - val_loss: 0.4689 - val_accuracy: 0.9090\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 79ms/step - loss: 0.4198 - accuracy: 0.9150 - val_loss: 0.4566 - val_accuracy: 0.9030\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16, validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f7df68d2-66fa-4714-8db1-78f8ee5de6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.8745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4681757092475891, 0.8744999766349792]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3986e4-bbfd-4162-b937-618f725cadbd",
   "metadata": {},
   "source": [
    "TO-DO:\n",
    "- model's accuracy improvement needs to be calculated\n",
    "- Drop in error rate (in percentile) needs to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0eeefc-e254-49bb-bd20-908043bfc67a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
