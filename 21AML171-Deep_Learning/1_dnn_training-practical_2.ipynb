{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e458d0-eeb7-47fc-8397-2b4133d9db6f",
   "metadata": {},
   "source": [
    "# Training Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc129ebe-d7ab-44d6-9ada-1c03f6d15113",
   "metadata": {},
   "source": [
    "## Practical 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b66544-447e-4368-9d19-1b9fd6528772",
   "metadata": {},
   "source": [
    "_**Experiment on Fashion MNIST or any other appropriate dataset to check if reusing pretrained layers in transfer learning makes the training possible with less data and saves training time. Also check for any model performance improvement.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231683f2-d3b4-457f-b392-a01108994cb3",
   "metadata": {},
   "source": [
    "First a model will be trained on set A (for classification task with 8 classes such as trousers, dresses, coats, sandals, shirts, sneakers, bags, and ankle boots in Fashion MNIST dataset). Then the learning will be reused for another a binary classification task on set B (the remaining 2 classes such as T-shirts/tops and pullovers in the saame dataset) since classes in set A are somewhat similar to classes in set B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53479574-53f9-4e32-b96a-9ade44a7e4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports required packages\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d1bacd1-7c13-4076-8a24-b637379fe448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loads fashion mnist dataset\n",
    "fashion = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a5a6b03-2bcd-4dfa-8845-36f7848446dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Considering dataset is organized in tuple, items are referenced as follows\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb904468-8537-407c-ac8a-7b7310bef2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (60000, 28, 28) \n",
      "Test dataset shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Checks the shape of the datasets\n",
    "print(\"Train dataset shape:\", X_train_full.shape,\n",
    "      \"\\nTest dataset shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "889aa6a0-b345-441a-b46d-d2a5a3278893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each training and test example is assigned to one of the following labels.\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \\\n",
    "               \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3cd7a4-7131-4c30-93a1-9f349d765d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizes the data between 0 and 1 for effective neural network model training\n",
    "X_train_full, X_test = X_train_full / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "908dfc4a-d5f4-4d52-9f68-76f4641ed489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splits train dataset further to seperate 5000 instances to be used as validation set\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=5000, random_state=42, stratify=y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb12e04-a37e-4713-8aba-420da4b94609",
   "metadata": {},
   "source": [
    "**Splits Fashion MNIST into tasks A and B, then train and save.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "198021a2-314f-42e3-b75e-87e756186cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stores class ids of the target items into variables.\n",
    "# In this case, variable pos_class_id and neg_class_id will store 2 and 0, respectively.\n",
    "# Also, item \"Pullover\" and \"T-shirt/top\" are considered as positive and negative class, respectively.\n",
    "\n",
    "pos_class_id = class_names.index(\"Pullover\")\n",
    "neg_class_id = class_names.index(\"T-shirt/top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05f00fff-4181-4135-b4c7-913a9f93a506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    \"\"\"\n",
    "    Splits the dataset having all items into a pair of tuples - one for dataset for 8-class classification task\n",
    "    and other one for dataset for the remaining 2-class classification task.\n",
    "    \"\"\"\n",
    "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
    "    y_A = y[~y_for_B]\n",
    "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
    "    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
    "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
    "        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A\n",
    "        \n",
    "    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5461b2bd-2b28-4c93-98af-057b105b6f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splits train, validation and test data into respective dataset for classification task A and B\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_val_A, y_val_A), (X_val_B, y_val_B) = split_dataset(X_val, y_val)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "\n",
    "# Considers only 200 instances for training for classification task B\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2903a952-c1c1-4f78-9938-1badf74ca16e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates a dense nueral network for classification task A\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_A = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abc9d6bf-32da-4671-9e46-bdcb327e0867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 1.1326 - accuracy: 0.6558 - val_loss: 0.7083 - val_accuracy: 0.7832\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 7s 5ms/step - loss: 0.5987 - accuracy: 0.8101 - val_loss: 0.5215 - val_accuracy: 0.8322\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 7s 5ms/step - loss: 0.4805 - accuracy: 0.8459 - val_loss: 0.4399 - val_accuracy: 0.8633\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 9s 7ms/step - loss: 0.4224 - accuracy: 0.8627 - val_loss: 0.3907 - val_accuracy: 0.8775\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 12s 9ms/step - loss: 0.3863 - accuracy: 0.8726 - val_loss: 0.3696 - val_accuracy: 0.8825\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 13s 9ms/step - loss: 0.3609 - accuracy: 0.8797 - val_loss: 0.3438 - val_accuracy: 0.8903\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 9s 6ms/step - loss: 0.3424 - accuracy: 0.8847 - val_loss: 0.3216 - val_accuracy: 0.8945\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 8s 6ms/step - loss: 0.3274 - accuracy: 0.8894 - val_loss: 0.3096 - val_accuracy: 0.9007\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 7s 5ms/step - loss: 0.3160 - accuracy: 0.8937 - val_loss: 0.3011 - val_accuracy: 0.9055\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 10s 7ms/step - loss: 0.3062 - accuracy: 0.8958 - val_loss: 0.2919 - val_accuracy: 0.9062\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 9s 6ms/step - loss: 0.2978 - accuracy: 0.8985 - val_loss: 0.2839 - val_accuracy: 0.9090\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 6s 4ms/step - loss: 0.2906 - accuracy: 0.9015 - val_loss: 0.2777 - val_accuracy: 0.9137\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2844 - accuracy: 0.9032 - val_loss: 0.2723 - val_accuracy: 0.9103\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2786 - accuracy: 0.9051 - val_loss: 0.2660 - val_accuracy: 0.9147\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2735 - accuracy: 0.9062 - val_loss: 0.2635 - val_accuracy: 0.9168\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 6s 5ms/step - loss: 0.2689 - accuracy: 0.9085 - val_loss: 0.2572 - val_accuracy: 0.9195\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 5s 4ms/step - loss: 0.2647 - accuracy: 0.9100 - val_loss: 0.2555 - val_accuracy: 0.9202\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 7s 5ms/step - loss: 0.2611 - accuracy: 0.9103 - val_loss: 0.2503 - val_accuracy: 0.9195\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 10s 7ms/step - loss: 0.2570 - accuracy: 0.9120 - val_loss: 0.2475 - val_accuracy: 0.9222\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 10s 7ms/step - loss: 0.2535 - accuracy: 0.9138 - val_loss: 0.2455 - val_accuracy: 0.9210\n"
     ]
    }
   ],
   "source": [
    "# Fits the model.\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=20, validation_data=(X_val_A, y_val_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4ab4e83-f36a-4101-b3fd-f7bd07877147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/my_fashion_mnist_model_A/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/my_fashion_mnist_model_A/assets\n"
     ]
    }
   ],
   "source": [
    "# Saves the model to be used later for transfer learning\n",
    "# NOTE: Make sure the folder \"models\" exists under the current working directory\n",
    "\n",
    "model_A.save(\"./models/my_fashion_mnist_model_A.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07111be1-06f8-4eb1-b842-8af9c808dabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c45b8c0-8afa-4cfb-985d-cb66f1052e89",
   "metadata": {},
   "source": [
    "Now, to realize whether if transfer learning works or not, first train model B, then evaluate it, without reusing model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf13b8e5-51f3-4ff2-97ed-18a4560565ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dense nueral network for classification task B\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_B = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1630dfd8-83f4-419a-bacc-5fa82f952be4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.7406 - accuracy: 0.4150 - val_loss: 0.6996 - val_accuracy: 0.4610\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.7003 - accuracy: 0.4350 - val_loss: 0.6684 - val_accuracy: 0.5350\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6688 - accuracy: 0.5600 - val_loss: 0.6431 - val_accuracy: 0.7030\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.6429 - accuracy: 0.6850 - val_loss: 0.6235 - val_accuracy: 0.7810\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.6230 - accuracy: 0.7600 - val_loss: 0.6069 - val_accuracy: 0.8150\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.6064 - accuracy: 0.8000 - val_loss: 0.5911 - val_accuracy: 0.8390\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5903 - accuracy: 0.8200 - val_loss: 0.5772 - val_accuracy: 0.8440\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5753 - accuracy: 0.8100 - val_loss: 0.5642 - val_accuracy: 0.8600\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.5622 - accuracy: 0.8200 - val_loss: 0.5521 - val_accuracy: 0.8760\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 0.5498 - accuracy: 0.8500 - val_loss: 0.5403 - val_accuracy: 0.8850\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.5379 - accuracy: 0.8700 - val_loss: 0.5298 - val_accuracy: 0.8920\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 1s 82ms/step - loss: 0.5271 - accuracy: 0.8800 - val_loss: 0.5198 - val_accuracy: 0.8990\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.5169 - accuracy: 0.9000 - val_loss: 0.5102 - val_accuracy: 0.9070\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5072 - accuracy: 0.9150 - val_loss: 0.5007 - val_accuracy: 0.9130\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4974 - accuracy: 0.9250 - val_loss: 0.4915 - val_accuracy: 0.9100\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4877 - accuracy: 0.9300 - val_loss: 0.4828 - val_accuracy: 0.9140\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.4786 - accuracy: 0.9250 - val_loss: 0.4739 - val_accuracy: 0.9190\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.4697 - accuracy: 0.9250 - val_loss: 0.4653 - val_accuracy: 0.9190\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4611 - accuracy: 0.9350 - val_loss: 0.4566 - val_accuracy: 0.9220\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.4527 - accuracy: 0.9450 - val_loss: 0.4479 - val_accuracy: 0.9310\n"
     ]
    }
   ],
   "source": [
    "# Fits the model.\n",
    "history = model_B.fit(X_train_B, y_train_B, epochs=20, validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93c680e5-e1e4-4b3a-b622-19ae359de421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.9205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45464184880256653, 0.9204999804496765]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluates the model on test dataset\n",
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a102c1-7989-4cdf-9d72-cd09b9c89493",
   "metadata": {},
   "source": [
    "Model B reaches 92.04% accuracy on the test set. Now let's try reusing the pretrained model A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d79bd98-5b33-4444-8057-b7a18f316032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loads the model trained for classification task A\n",
    "model_A = tf.keras.models.load_model(\"./models/my_fashion_mnist_model_A.keras\")\n",
    "\n",
    "# Creates a new model copies all the layers, except for the output layer, from model A\n",
    "# to be reused for classification task B\n",
    "model_B_on_A = tf.keras.Sequential(model_A.layers[:-1])\n",
    "\n",
    "# Just one-node output layer is added into the new model\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61577729-0c7e-45db-8279-b4907bc3d3d4",
   "metadata": {},
   "source": [
    "As model_B_on_A and model_A actually share layers now, training one will update both models. To avoid that model_B_on_A should be built on top of a clone of model_A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be0f8c02-de3b-4fd8-9524-49201c8f80dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Network architecture of model A is cloned into a new model\n",
    "model_A_clone = tf.keras.models.clone_model(model_A)\n",
    "\n",
    "# Learned weigts of the model A are copied into the new cloned model\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6d886bf8-57dc-4b99-b070-a0aa559a9273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates model_B_on_A just like in the previous cell\n",
    "\n",
    "# Like the previous steps, creates target model B cloning all layers, except for the output layer,\n",
    "# and then adds a one-node output layer onto it\n",
    "\n",
    "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fe40df-1152-4a02-8195-dbae064b82da",
   "metadata": {},
   "source": [
    "**Target model's training takes place into two phases. In the first phase, only output layer gets trained over a shorter iterations keeping all hidden layers non-trainable, and in the second phase, all layers are trained over a relatively longer iterations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b51bbea-ef3c-407a-9ad7-08be854768a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freezes all the hidden layers before training\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f75bb9df-22ff-46cd-92fc-ba71f9c2b586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 0.8908 - accuracy: 0.5250 - val_loss: 0.7991 - val_accuracy: 0.5050\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.7271 - accuracy: 0.5750 - val_loss: 0.7215 - val_accuracy: 0.5580\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6843 - accuracy: 0.6050 - val_loss: 0.6976 - val_accuracy: 0.5800\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.6639 - accuracy: 0.6650 - val_loss: 0.6678 - val_accuracy: 0.6320\n"
     ]
    }
   ],
   "source": [
    "# Fits the model over a shorter iteration to train only the output layer\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9216bbf9-5944-48bd-8b8a-3d3a5749885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then allows hidden layers trainable before next iterations of training\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df1e2d84-f381-4eb2-b4cb-c080940f4e28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 52ms/step - loss: 0.6206 - accuracy: 0.6900 - val_loss: 0.5894 - val_accuracy: 0.7440\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5528 - accuracy: 0.8100 - val_loss: 0.5388 - val_accuracy: 0.8050\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5014 - accuracy: 0.8600 - val_loss: 0.5111 - val_accuracy: 0.8100\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.4588 - accuracy: 0.8650 - val_loss: 0.4579 - val_accuracy: 0.8860\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4233 - accuracy: 0.9000 - val_loss: 0.4297 - val_accuracy: 0.8950\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3972 - accuracy: 0.9150 - val_loss: 0.4025 - val_accuracy: 0.9110\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3678 - accuracy: 0.9350 - val_loss: 0.3990 - val_accuracy: 0.8950\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3514 - accuracy: 0.9200 - val_loss: 0.3646 - val_accuracy: 0.9240\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3306 - accuracy: 0.9400 - val_loss: 0.3489 - val_accuracy: 0.9270\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3139 - accuracy: 0.9450 - val_loss: 0.3353 - val_accuracy: 0.9280\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3007 - accuracy: 0.9450 - val_loss: 0.3260 - val_accuracy: 0.9290\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2898 - accuracy: 0.9450 - val_loss: 0.3142 - val_accuracy: 0.9290\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2796 - accuracy: 0.9500 - val_loss: 0.3068 - val_accuracy: 0.9290\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2709 - accuracy: 0.9500 - val_loss: 0.2959 - val_accuracy: 0.9320\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2604 - accuracy: 0.9600 - val_loss: 0.2901 - val_accuracy: 0.9310\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2525 - accuracy: 0.9600 - val_loss: 0.2819 - val_accuracy: 0.9320\n"
     ]
    }
   ],
   "source": [
    "# Fits the full model.\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16, validation_data=(X_val_B, y_val_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f7df68d2-66fa-4714-8db1-78f8ee5de6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2919 - accuracy: 0.9270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2919308841228485, 0.9269999861717224]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once again, evaluates the model B against test dataset\n",
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a839775-07b4-43b9-889c-8bfce26e368f",
   "metadata": {},
   "source": [
    "The evaluation shows that there is 0.65% [92.69 - 92.04] improvement in accuracy and it indicates that error drop rate is 8% [1 - (100 - 92.69) / (100 - 92.04)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623bd01-aebd-4f13-afd3-b2d7357c6b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
