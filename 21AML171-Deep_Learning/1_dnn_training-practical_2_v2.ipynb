{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e458d0-eeb7-47fc-8397-2b4133d9db6f",
   "metadata": {},
   "source": [
    "# TRANSFER LEARNING FOR IMPROVED MODEL WITH LESS DATA\n",
    "\n",
    "_**Applies transfer learning to reuse pretrained layers to experiment if it improves model performance with less data.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b66544-447e-4368-9d19-1b9fd6528772",
   "metadata": {},
   "source": [
    "**High-level Steps:**\n",
    "\n",
    "1. Instead of taking an already trained model (containing pretrained layers), a model gets trained in this experiment to be considered as a pretrained model. To train that model, data for 8 classes out of total 10 classes in Fashion MNIST dataset are used. This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images.\n",
    "a drop-in replacement for MNIST.\n",
    "\n",
    "2. Then a binary classification model (the target model) gets trained (from scratch) on the data from remaining two clssses from the same dataset and its prediction performance gets observed.\n",
    "\n",
    "3. Then the same classification model is build by apply transfer learning using pretrained layers from the model created in first step.\n",
    "\n",
    "4. Lastly the prediction performance of the target model is compared with that of the model created in the second step. Also, analysis is performed to appreciate if transfer learning speeds up training and make training possible with less data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53479574-53f9-4e32-b96a-9ade44a7e4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 18:03:15.290541: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-15 18:03:15.291296: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-15 18:03:15.294956: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-15 18:03:15.306398: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739622795.326201  132940 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739622795.331946  132940 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-15 18:03:15.355630: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports required packages\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867c98b",
   "metadata": {},
   "source": [
    "## Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1bacd1-7c13-4076-8a24-b637379fe448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loads fashion mnist dataset\n",
    "fashion = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a47db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each training and test example is assigned to one of the following labels.\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \\\n",
    "               \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a5a6b03-2bcd-4dfa-8845-36f7848446dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Considering dataset is organized in tuple, items are referenced as follows\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb904468-8537-407c-ac8a-7b7310bef2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (60000, 28, 28)\n",
      "Test dataset shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Checks the shape of the datasets\n",
    "print(\"Train dataset shape:\", X_train_full.shape)\n",
    "print(\"Test dataset shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2926872b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks the data type of the data\n",
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80881185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the labels for refer to the class index\n",
    "y_train_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5066382a",
   "metadata": {},
   "source": [
    "Considering the target binary classification model is expected to classify \"Pullover\" and \"T-shirt/top\", it separates data for these two classes leaving data for remaining 8 classes to build a model to be considered as pretrained model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "072b8701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of class_0: 2\n",
      "Index of class_1: 0\n"
     ]
    }
   ],
   "source": [
    "# Finds the index for the target class \"Pullover\" and \"T-shirt/top\" as\n",
    "# dataset labels contains class indexes instead of class names\n",
    "\n",
    "class_0_index = class_names.index(\"Pullover\")\n",
    "class_1_index = class_names.index(\"T-shirt/top\")\n",
    "\n",
    "print(\"Index of class_0:\", class_0_index)\n",
    "print(\"Index of class_1:\", class_1_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e44df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, False, True, True, False, True, False, False]\n"
     ]
    }
   ],
   "source": [
    "# Gets the indexes of training label containing either classes\n",
    "class_0_1_index_flag = [True if (x==class_0_index or x==class_1_index) else False for x in y_train_full]\n",
    "\n",
    "# Shows few flags \n",
    "print(class_0_1_index_flag[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbdd1f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperates dataset containing data for two classes\n",
    "X_train_2_classes_full = X_train_full[class_0_1_index_flag]\n",
    "\n",
    "# Checks the shape of the dataset\n",
    "X_train_2_classes_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "236e3386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, False, True, False, False, True, False, True, True]\n"
     ]
    }
   ],
   "source": [
    "# Flips bool values (True to False and False to True) to get the flags against\n",
    "# other classes in the training label\n",
    "class_0_1_index_flag_flipped = [not flag for flag in class_0_1_index_flag]\n",
    "\n",
    "# Shows few flags \n",
    "print(class_0_1_index_flag_flipped[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79042b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperates dataset containing data for the remaining 8 classes\n",
    "X_train_8_classes_full = X_train_full[class_0_1_index_flag_flipped]\n",
    "\n",
    "# Checks the shape of the dataset\n",
    "X_train_8_classes_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0e68eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of the first dimension value of both the dataset should be equal to the total number of training instances\n",
    "X_train_2_classes_full.shape[0] + X_train_8_classes_full.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24c9a537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000,)\n",
      "(48000,)\n"
     ]
    }
   ],
   "source": [
    "# Similarly, separates targets to contain only respective labels\n",
    "y_train_2_classes_full = y_train_full[class_0_1_index_flag]\n",
    "y_train_8_classes_full = y_train_full[class_0_1_index_flag_flipped]\n",
    "\n",
    "# Checks the shape of the targets\n",
    "print(y_train_2_classes_full.shape)\n",
    "print(y_train_8_classes_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914aeec",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85264c",
   "metadata": {},
   "source": [
    "### Training Model to be Considered as Pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9c4ce5",
   "metadata": {},
   "source": [
    "**Preprocesses Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f73cd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates validation dataset\n",
    "X_train_8_classes, X_val_8_classes, y_train_8_classes, y_val_8_classes = train_test_split(\n",
    "    X_train_8_classes_full, y_train_8_classes_full, test_size=5000, random_state=42, stratify=y_train_8_classes_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdf7f698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43000, 28, 28)\n",
      "(5000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Prints the shape of the separated datasets both containing 8 classes\n",
    "print(X_train_8_classes.shape)\n",
    "print(X_val_8_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "202c27a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then standardizes the datasets by first calculating mean and standard deviation, and then\n",
    "# by subtracting the mean from the data and then dividing the data by standard deviation\n",
    "\n",
    "pixel_means_8_classes = X_train_8_classes.mean(axis=0, keepdims=True)\n",
    "pixel_stds_8_classes = X_train_8_classes.std(axis=0, keepdims=True)\n",
    "\n",
    "X_train_8_classes_scaled = (X_train_8_classes - pixel_means_8_classes) / pixel_stds_8_classes\n",
    "X_val_8_classes_scaled = (X_val_8_classes - pixel_means_8_classes) / pixel_stds_8_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "813259ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the labels ranges from [1, 3, 4, 5, 6, 7, 8, 9], it normalizes the label from 0 through 7\n",
    "label_encoder_8_classes = LabelEncoder()\n",
    "y_train_8_classes_encoded = label_encoder_8_classes.fit_transform(y_train_8_classes)\n",
    "y_val_8_classes_encoded = label_encoder_8_classes.transform(y_val_8_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4bba81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pradip/anaconda3/envs/keras3/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-02-15 18:03:18.964372: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Initializes the following densed neural network with arbirary number of layers and compiles it\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84c14db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">808</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m78,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m808\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,508</span> (388.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,508\u001b[0m (388.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,508</span> (388.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,508\u001b[0m (388.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checks for model summary [optional]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6263c6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6154 - loss: 1.1450 - val_accuracy: 0.8316 - val_loss: 0.4857\n",
      "Epoch 2/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.4601 - val_accuracy: 0.8618 - val_loss: 0.3884\n",
      "Epoch 3/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 0.3840 - val_accuracy: 0.8770 - val_loss: 0.3446\n",
      "Epoch 4/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8807 - loss: 0.3361 - val_accuracy: 0.8848 - val_loss: 0.3196\n",
      "Epoch 5/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8893 - loss: 0.3130 - val_accuracy: 0.8922 - val_loss: 0.3003\n",
      "Epoch 6/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8978 - loss: 0.2907 - val_accuracy: 0.8982 - val_loss: 0.2883\n",
      "Epoch 7/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9022 - loss: 0.2782 - val_accuracy: 0.9048 - val_loss: 0.2757\n",
      "Epoch 8/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9096 - loss: 0.2647 - val_accuracy: 0.9080 - val_loss: 0.2679\n",
      "Epoch 9/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9092 - loss: 0.2588 - val_accuracy: 0.9094 - val_loss: 0.2613\n",
      "Epoch 10/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2522 - val_accuracy: 0.9106 - val_loss: 0.2544\n",
      "Epoch 11/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9169 - loss: 0.2405 - val_accuracy: 0.9132 - val_loss: 0.2497\n",
      "Epoch 12/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9201 - loss: 0.2320 - val_accuracy: 0.9144 - val_loss: 0.2462\n",
      "Epoch 13/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9217 - loss: 0.2284 - val_accuracy: 0.9144 - val_loss: 0.2422\n",
      "Epoch 14/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9225 - loss: 0.2235 - val_accuracy: 0.9166 - val_loss: 0.2389\n",
      "Epoch 15/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2147 - val_accuracy: 0.9186 - val_loss: 0.2357\n",
      "Epoch 16/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.2090 - val_accuracy: 0.9186 - val_loss: 0.2324\n",
      "Epoch 17/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9291 - loss: 0.2046 - val_accuracy: 0.9174 - val_loss: 0.2307\n",
      "Epoch 18/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.2044 - val_accuracy: 0.9192 - val_loss: 0.2285\n",
      "Epoch 19/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9323 - loss: 0.1961 - val_accuracy: 0.9192 - val_loss: 0.2259\n",
      "Epoch 20/20\n",
      "\u001b[1m1344/1344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9326 - loss: 0.1936 - val_accuracy: 0.9190 - val_loss: 0.2257\n"
     ]
    }
   ],
   "source": [
    "# Fits the model over specific number iterations (epochs) and validation data\n",
    "# to observe the learning performance during training\n",
    "model_history = model.fit(X_train_8_classes_scaled, y_train_8_classes_encoded, epochs=20, \n",
    "                          validation_data=(X_val_8_classes_scaled, y_val_8_classes_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "720495a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the trained model on disk to be used as pretrained model later.\n",
    "# NOTE: Folder \"model\" must exist for model file to be saved into.\n",
    "model.save(\"./models/my_fashion_mnist_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6498c",
   "metadata": {},
   "source": [
    "### Training Target Model from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf11268",
   "metadata": {},
   "source": [
    "**Preprocesses Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ef717e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates validation dataset from the data containg 2 classes\n",
    "X_train_2_classes, X_val_2_classes, y_train_2_classes, y_val_2_classes = train_test_split(\n",
    "    X_train_2_classes_full, y_train_2_classes_full, test_size=3000, random_state=42, stratify=y_train_2_classes_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bd90c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 28, 28)\n",
      "(3000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Prints the shape of the separated datasets containing both classes\n",
    "print(X_train_2_classes.shape)\n",
    "print(X_val_2_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b48e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then standardizes the datasets by first calculating mean and standard deviation, and then\n",
    "# by subtracting the mean from the data and then dividing the data by standard deviation\n",
    "\n",
    "pixel_means_2_classes = X_train_2_classes.mean(axis=0, keepdims=True)\n",
    "pixel_stds_2_classes = X_train_2_classes.std(axis=0, keepdims=True)\n",
    "\n",
    "X_train_2_classes_scaled = (X_train_2_classes - pixel_means_2_classes) / pixel_stds_2_classes\n",
    "X_val_2_classes_scaled = (X_val_2_classes - pixel_means_2_classes) / pixel_stds_2_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b396624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the labels ranges from [1, 3, 4, 5, 6, 7, 8, 9], it normalizes the label from 0 through 7\n",
    "\n",
    "label_encoder_2_classes = LabelEncoder()\n",
    "y_train_2_classes_encoded = label_encoder_2_classes.fit_transform(y_train_2_classes)\n",
    "y_val_2_classes_encoded = label_encoder_2_classes.transform(y_val_2_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7cf78c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pradip/anaconda3/envs/keras3/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Clears the name counters and \n",
    "# sets the global random seed for operations that rely on a random seed\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Initializes the following densed neural network with arbirary number of layers and compiles it\n",
    "model_from_scratch = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_from_scratch.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), \n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55499942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m78,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,801</span> (385.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m98,801\u001b[0m (385.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,801</span> (385.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,801\u001b[0m (385.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checks for model summary [optional]\n",
    "model_from_scratch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5422917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6550 - loss: 0.6034 - val_accuracy: 0.9407 - val_loss: 0.2608\n",
      "Epoch 2/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.2398 - val_accuracy: 0.9570 - val_loss: 0.1776\n",
      "Epoch 3/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1691 - val_accuracy: 0.9577 - val_loss: 0.1502\n",
      "Epoch 4/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9552 - loss: 0.1415 - val_accuracy: 0.9607 - val_loss: 0.1382\n",
      "Epoch 5/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9585 - loss: 0.1271 - val_accuracy: 0.9617 - val_loss: 0.1319\n",
      "Epoch 6/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9608 - loss: 0.1181 - val_accuracy: 0.9620 - val_loss: 0.1279\n",
      "Epoch 7/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1119 - val_accuracy: 0.9627 - val_loss: 0.1251\n",
      "Epoch 8/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9637 - loss: 0.1070 - val_accuracy: 0.9633 - val_loss: 0.1230\n",
      "Epoch 9/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.1031 - val_accuracy: 0.9647 - val_loss: 0.1213\n",
      "Epoch 10/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9659 - loss: 0.0994 - val_accuracy: 0.9647 - val_loss: 0.1199\n",
      "Epoch 11/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9664 - loss: 0.0970 - val_accuracy: 0.9647 - val_loss: 0.1186\n",
      "Epoch 12/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9668 - loss: 0.0945 - val_accuracy: 0.9650 - val_loss: 0.1175\n",
      "Epoch 13/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9688 - loss: 0.0922 - val_accuracy: 0.9657 - val_loss: 0.1166\n",
      "Epoch 14/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9699 - loss: 0.0902 - val_accuracy: 0.9657 - val_loss: 0.1158\n",
      "Epoch 15/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9698 - loss: 0.0883 - val_accuracy: 0.9657 - val_loss: 0.1151\n",
      "Epoch 16/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9709 - loss: 0.0865 - val_accuracy: 0.9650 - val_loss: 0.1144\n",
      "Epoch 17/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9709 - loss: 0.0848 - val_accuracy: 0.9650 - val_loss: 0.1137\n",
      "Epoch 18/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9715 - loss: 0.0833 - val_accuracy: 0.9650 - val_loss: 0.1131\n",
      "Epoch 19/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0818 - val_accuracy: 0.9647 - val_loss: 0.1125\n",
      "Epoch 20/20\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9721 - loss: 0.0804 - val_accuracy: 0.9653 - val_loss: 0.1120\n"
     ]
    }
   ],
   "source": [
    "# Fits the model over specific number iterations (epochs) on all the training data available for the 2 classes\n",
    "# and validation data to observe the learning performance during training\n",
    "model_from_scratch_history = model_from_scratch.fit(X_train_2_classes_scaled, y_train_2_classes_encoded, epochs=20, \n",
    "                                                    validation_data=(X_val_2_classes_scaled, y_val_2_classes_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb96e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the indexes of test label containing either classes\n",
    "class_0_1_index_flag = [True if (x==class_0_index or x==class_1_index) else False for x in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "534c1e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperates dataset containing data for two classes from the whole test set also containing other classes\n",
    "X_test_2_classes = X_test[class_0_1_index_flag]\n",
    "\n",
    "# Checks the shape of the dataset\n",
    "X_test_2_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eec00375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, separates targets to contain only respective labels\n",
    "y_test_2_classes = y_test[class_0_1_index_flag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6c854ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizes the test labels for the 2 classes using the already fitted encoder\n",
    "y_test_2_classes_encoded = label_encoder_2_classes.transform(y_test_2_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67020685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the encoded classes for reference\n",
    "y_test_2_classes_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43ef1670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizes the test set by subtracting the mean from the data and then dividing the data by standard deviation\n",
    "X_test_2_classes_scaled = (X_test_2_classes - pixel_means_2_classes) / pixel_stds_2_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c72e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.9610 - loss: 0.1085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11099033057689667, 0.9624999761581421]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluates the test prediction performance on the model built from scratch\n",
    "model_from_scratch.evaluate(X_test_2_classes_scaled, y_test_2_classes_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda4cbe",
   "metadata": {},
   "source": [
    "The above model that was built from scratch over **9000** [12000 total - 3000 validation instances] training instances containing data for 2 classes, reached **96.24%** accuracy in test set. The experiment continues to apply transfer learning by reusing pretrained layers from first model built over other 8 classes to check if new model trained over less data can achieve accuracy from the model built from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67143f0",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4623bd01-aebd-4f13-afd3-b2d7357c6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the saved model created to be used as pretrained model\n",
    "model_using_pretrained_layers = tf.keras.models.load_model(\"./models/my_fashion_mnist_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "43d00b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">808</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m78,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m808\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,510</span> (388.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,510\u001b[0m (388.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,508</span> (388.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,508\u001b[0m (388.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checks the model summary especially to refer to the last layer i.e. the output layer\n",
    "model_using_pretrained_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "77c11c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m78,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,803</span> (385.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m98,803\u001b[0m (385.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,801</span> (385.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,801\u001b[0m (385.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Removes the last layer (containing 8 output) to add task specific binary output layer\n",
    "model_using_pretrained_layers.pop()\n",
    "\n",
    "# And then adds a binary output layer\n",
    "model_using_pretrained_layers.add(tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\"))\n",
    "\n",
    "# Then verifies the same visualizing the model summary\n",
    "model_using_pretrained_layers.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8ea620",
   "metadata": {},
   "source": [
    "**Fine-tuning already pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65abaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considers only 70% of the 2-classes training set to check the effectiveness of the transfer learning\n",
    "\n",
    "X_train_2_classes_scaled_subset, _, y_train_2_classes_encoded_subset, _ = train_test_split(\n",
    "    X_train_2_classes_scaled, y_train_2_classes_encoded, train_size=0.70, stratify=y_train_2_classes_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "440c1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First sets all the pretrained layers (except for the newly added output layer) non-trainable\n",
    "for layer in model_using_pretrained_layers.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2468 - loss: 1.1377 - val_accuracy: 0.6753 - val_loss: 0.6206\n",
      "Epoch 2/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7705 - loss: 0.5438 - val_accuracy: 0.8813 - val_loss: 0.4155\n",
      "Epoch 3/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8891 - loss: 0.3884 - val_accuracy: 0.9040 - val_loss: 0.3423\n",
      "Epoch 4/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9046 - loss: 0.3290 - val_accuracy: 0.9137 - val_loss: 0.3056\n",
      "Epoch 5/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2979 - val_accuracy: 0.9167 - val_loss: 0.2833\n",
      "Epoch 6/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9156 - loss: 0.2786 - val_accuracy: 0.9213 - val_loss: 0.2682\n",
      "Epoch 7/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9206 - loss: 0.2653 - val_accuracy: 0.9233 - val_loss: 0.2571\n",
      "Epoch 8/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9215 - loss: 0.2554 - val_accuracy: 0.9240 - val_loss: 0.2485\n",
      "Epoch 9/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.2476 - val_accuracy: 0.9240 - val_loss: 0.2416\n",
      "Epoch 10/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9241 - loss: 0.2413 - val_accuracy: 0.9257 - val_loss: 0.2359\n"
     ]
    }
   ],
   "source": [
    "# Then trains just the output layer over lower learning rate and relatively lesser number of training iterations\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_using_pretrained_layers.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001))\n",
    "\n",
    "model_using_pretrained_layers_history = model_using_pretrained_layers.fit(\n",
    "    X_train_2_classes_scaled_subset, y_train_2_classes_encoded_subset, epochs=10, \n",
    "    validation_data=(X_val_2_classes_scaled, y_val_2_classes_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7278c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.2202 - val_accuracy: 0.9400 - val_loss: 0.1802\n",
      "Epoch 2/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.1745 - val_accuracy: 0.9460 - val_loss: 0.1575\n",
      "Epoch 3/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9504 - loss: 0.1519 - val_accuracy: 0.9517 - val_loss: 0.1453\n",
      "Epoch 4/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1375 - val_accuracy: 0.9543 - val_loss: 0.1374\n",
      "Epoch 5/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.1270 - val_accuracy: 0.9553 - val_loss: 0.1320\n",
      "Epoch 6/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9605 - loss: 0.1190 - val_accuracy: 0.9560 - val_loss: 0.1279\n",
      "Epoch 7/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.1125 - val_accuracy: 0.9563 - val_loss: 0.1246\n",
      "Epoch 8/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.1074 - val_accuracy: 0.9573 - val_loss: 0.1219\n",
      "Epoch 9/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9652 - loss: 0.1034 - val_accuracy: 0.9580 - val_loss: 0.1197\n",
      "Epoch 10/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9676 - loss: 0.1000 - val_accuracy: 0.9587 - val_loss: 0.1178\n",
      "Epoch 11/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9684 - loss: 0.0970 - val_accuracy: 0.9593 - val_loss: 0.1161\n",
      "Epoch 12/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.0944 - val_accuracy: 0.9600 - val_loss: 0.1147\n",
      "Epoch 13/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9691 - loss: 0.0921 - val_accuracy: 0.9600 - val_loss: 0.1134\n",
      "Epoch 14/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0900 - val_accuracy: 0.9613 - val_loss: 0.1123\n",
      "Epoch 15/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.0880 - val_accuracy: 0.9617 - val_loss: 0.1112\n",
      "Epoch 16/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0862 - val_accuracy: 0.9623 - val_loss: 0.1102\n",
      "Epoch 17/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0845 - val_accuracy: 0.9623 - val_loss: 0.1093\n",
      "Epoch 18/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0830 - val_accuracy: 0.9633 - val_loss: 0.1085\n",
      "Epoch 19/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0815 - val_accuracy: 0.9637 - val_loss: 0.1077\n",
      "Epoch 20/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.0801 - val_accuracy: 0.9643 - val_loss: 0.1069\n",
      "Epoch 21/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9732 - loss: 0.0787 - val_accuracy: 0.9643 - val_loss: 0.1062\n",
      "Epoch 22/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9734 - loss: 0.0774 - val_accuracy: 0.9647 - val_loss: 0.1056\n",
      "Epoch 23/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9741 - loss: 0.0762 - val_accuracy: 0.9653 - val_loss: 0.1050\n",
      "Epoch 24/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9743 - loss: 0.0751 - val_accuracy: 0.9653 - val_loss: 0.1044\n",
      "Epoch 25/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.0739 - val_accuracy: 0.9660 - val_loss: 0.1039\n",
      "Epoch 26/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.0729 - val_accuracy: 0.9663 - val_loss: 0.1034\n",
      "Epoch 27/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9745 - loss: 0.0718 - val_accuracy: 0.9667 - val_loss: 0.1030\n",
      "Epoch 28/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9757 - loss: 0.0708 - val_accuracy: 0.9670 - val_loss: 0.1026\n",
      "Epoch 29/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9759 - loss: 0.0699 - val_accuracy: 0.9670 - val_loss: 0.1022\n",
      "Epoch 30/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9768 - loss: 0.0689 - val_accuracy: 0.9673 - val_loss: 0.1018\n",
      "Epoch 31/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0680 - val_accuracy: 0.9670 - val_loss: 0.1014\n",
      "Epoch 32/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0671 - val_accuracy: 0.9673 - val_loss: 0.1011\n",
      "Epoch 33/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0662 - val_accuracy: 0.9667 - val_loss: 0.1008\n",
      "Epoch 34/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9769 - loss: 0.0654 - val_accuracy: 0.9670 - val_loss: 0.1005\n",
      "Epoch 35/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0645 - val_accuracy: 0.9670 - val_loss: 0.1002\n",
      "Epoch 36/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0637 - val_accuracy: 0.9670 - val_loss: 0.0999\n",
      "Epoch 37/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0630 - val_accuracy: 0.9670 - val_loss: 0.0997\n",
      "Epoch 38/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9785 - loss: 0.0622 - val_accuracy: 0.9673 - val_loss: 0.0994\n",
      "Epoch 39/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9785 - loss: 0.0614 - val_accuracy: 0.9677 - val_loss: 0.0992\n",
      "Epoch 40/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0607 - val_accuracy: 0.9677 - val_loss: 0.0990\n",
      "Epoch 41/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9791 - loss: 0.0600 - val_accuracy: 0.9677 - val_loss: 0.0988\n",
      "Epoch 42/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9792 - loss: 0.0589 - val_accuracy: 0.9677 - val_loss: 0.0986\n",
      "Epoch 43/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9794 - loss: 0.0586 - val_accuracy: 0.9677 - val_loss: 0.0985\n",
      "Epoch 44/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9800 - loss: 0.0579 - val_accuracy: 0.9677 - val_loss: 0.0983\n",
      "Epoch 45/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0572 - val_accuracy: 0.9680 - val_loss: 0.0982\n",
      "Epoch 46/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0566 - val_accuracy: 0.9680 - val_loss: 0.0980\n",
      "Epoch 47/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.0560 - val_accuracy: 0.9680 - val_loss: 0.0979\n",
      "Epoch 48/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0553 - val_accuracy: 0.9680 - val_loss: 0.0978\n",
      "Epoch 49/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0547 - val_accuracy: 0.9680 - val_loss: 0.0977\n",
      "Epoch 50/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0541 - val_accuracy: 0.9683 - val_loss: 0.0976\n"
     ]
    }
   ],
   "source": [
    "# Now, makes all the pretrained layers trainable and performs retraining over \n",
    "# smaller learning rate and relatively longer training iterations\n",
    "\n",
    "for layer in model_using_pretrained_layers.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompiles the model due to change of trainability of the layers\n",
    "model_using_pretrained_layers.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "model_using_pretrained_layers_history = model_using_pretrained_layers.fit(\n",
    "   X_train_2_classes_scaled_subset, y_train_2_classes_encoded_subset, epochs=50, \n",
    "   validation_data=(X_val_2_classes_scaled, y_val_2_classes_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f3a11697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.9677 - loss: 0.0950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10547270625829697, 0.9664999842643738]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluates the test prediction performance on the model built using pretrained layers\n",
    "model_using_pretrained_layers.evaluate(X_test_2_classes_scaled, y_test_2_classes_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3aef32",
   "metadata": {},
   "source": [
    "Though this model built over pretrained layers using on 70% of the available training set, but could also achieved **96.64%** test accuracy as compared to **96.24%** accuracy of the model built from scratch over the full training set. The error rate was improved by **11.9%** [(96.64−96.24)÷(100−96.64)×100]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
