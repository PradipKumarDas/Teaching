{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c86d1f-22e4-43ee-9193-c91197f3b77a",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "\n",
    "In this tutorial, you will build your a image classifier with PyTorch. You will work with MNIST dataset that contain grayscale images of handwritten digits. It has 60,000 training images and 10,000 test images. Each of these are 28 by 28 pixels in \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ef216-062b-4181-9a55-5f834ef663ad",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9b02ec2-f6ab-494e-8508-fb4f46e96966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision                                 # PyTorch's computer vision library\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2\n",
    "from torch.utils.data import DataLoader            # Provides inbuilt datasets and sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca22567-9e42-4c0a-93a9-b71941568961",
   "metadata": {},
   "source": [
    "## Data Ingestion & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3477f2f-64da-4ba4-be17-340f11067282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines required data transformations (creating tensors followed by normalization)\n",
    "transform = transforms_v2.Compose([\n",
    "    # transforms.ToTensor(),    # Not recommended in transforms.v2\n",
    "    transforms_v2.ToImage(),    # Converts to tensor - only needed for PIL images\n",
    "    transforms_v2.ToDtype(torch.float32, scale=True),    # Requires only normalization that expects float input\n",
    "    transforms_v2.Normalize((0.1307,), (0.3081,))        # 0.1307 and 0.3081 are mean and std. dev. of the entire training set\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10b24bb9-18b9-4bbd-8d58-1002f7451e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the MNIST datasets\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./datasets/\",    # Root directory to keep dataset files\n",
    "    train=True,            # If 'True', loads train set, otherwise test set\n",
    "    transform=transform,   # Applies automatic transformation (defined in above cell in this case)\n",
    "    download=True          # If 'True', downloads the datasets if is not already downloaded\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./datasets\", train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60398948-c4dd-4b99-b03c-5b3d24fcb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates data loaders\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,    # Dataset the data to load from\n",
    "    batch_size=64,    # Samples (images) per batch to load\n",
    "    shuffle=True      # If 'True', shuffles the samples at every epoch for model to see samples in random order\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset\n",
    "    batch_size=1000,    # Larger batch size as no need for gradient calculation for testing\n",
    "    shuffle=False       # Shuffling is not required for testing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce1279f-cf5c-49d2-9f60-57ac15a33d4f",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1bd71c-1be2-4d8f-ace8-f376aea1e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a neural network for modeling\n",
    "class MNISTClassifier(nn.Module):    # Inheriting from `nn.module` gives all of PyTorch's neural network functionality\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Defines the layers\n",
    "        self.flatten = nn.Flatten()     # Flattens the 3-D image [channel, height, width],  as following linear layers expect flat vectors\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 128),        # Inputs: <batch_size> x 784, outputs: <batch_size> x 128\n",
    "            nn.ReLU(),                  # Activation function outputs only positive values zeroing negative values\n",
    "            nn.Linear(128, 10)          # Inputs: <batch_size> x 128, outputs: <batch_size> x 10 [10 outputs being one for each digit class]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instead of custom class, the layers can also be organized using class `nn.Sequential`.\n",
    "# model = nn.Sequential(\n",
    "#     nn.Flatten()\n",
    "#     nn.Linear(784, 128)\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(128, 10)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981ddeb-548b-4d8e-8dbd-a96f304d82d3",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6c750f4-66e3-42e1-913b-153801dc594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "# Checks for GPU and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "989efdc7-09f3-42e7-9875-1e7d6b1bb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes the model and moves to device\n",
    "model = MNISTClassifier().to(device)\n",
    "\n",
    "# Sets loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Sets optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09fc5af2-971e-4785-b30a-f393ae89b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, loss_function, optimizer, device):\n",
    "    \"\"\"\n",
    "    Trains a model using data loader over one epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Sets the mode into training\n",
    "\n",
    "    running_loss = 0.0\n",
    "    true_predictions = 0\n",
    "    sample_count = 0\n",
    "\n",
    "    # Training model over batches\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        \n",
    "        # Moves both data and targets to the device\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()    # Resets gradients before processing next batch\n",
    "        outputs = model(data)    # Model processes already transformed data that arrives in batches\n",
    "        loss = loss_function(outputs, targets)    # Computes the cross entropy loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Tracks improvement\n",
    "        running_loss += loss.item()             # Aggregates losses over 100 batches\n",
    "        _, predicted_class = outputs.max(dim=1)\n",
    "        sample_count += targets.size(0)         # Aggregates count of samples over 100 batches\n",
    "        true_predictions += predicted_class.eq(targets).sum().item()\n",
    "\n",
    "        # Shows progress with improvement\n",
    "        if (batch_idx % 100) == 0 and batch_idx > 0:\n",
    "            avg_loss = running_loss / 100\n",
    "            accuracy = true_predictions / sample_count * 100.0\n",
    "            print(f\"[Batch #: {batch_idx * 64}] Avg. Loss: {avg_loss:.3f}, Accuracy: {accuracy:.1f}%\") \n",
    "            running_loss = 0.0                  # Resets variable\n",
    "            true_predictions = 0\n",
    "            sample_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa10865-f048-4f11-8151-bc458a9527d2",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5173603-0014-4d8f-ab63-a9c28379a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "[Batch #: 6400] Avg. Loss: 0.627, Accuracy: 82.8%\n",
      "[Batch #: 12800] Avg. Loss: 0.350, Accuracy: 89.6%\n",
      "[Batch #: 19200] Avg. Loss: 0.272, Accuracy: 91.7%\n",
      "[Batch #: 25600] Avg. Loss: 0.225, Accuracy: 93.4%\n",
      "[Batch #: 32000] Avg. Loss: 0.210, Accuracy: 93.8%\n",
      "[Batch #: 38400] Avg. Loss: 0.194, Accuracy: 94.3%\n",
      "[Batch #: 44800] Avg. Loss: 0.160, Accuracy: 95.3%\n",
      "[Batch #: 51200] Avg. Loss: 0.154, Accuracy: 95.1%\n",
      "[Batch #: 57600] Avg. Loss: 0.147, Accuracy: 95.9%\n",
      "\n",
      "Epoch: 2\n",
      "[Batch #: 6400] Avg. Loss: 0.128, Accuracy: 96.4%\n",
      "[Batch #: 12800] Avg. Loss: 0.107, Accuracy: 96.8%\n",
      "[Batch #: 19200] Avg. Loss: 0.114, Accuracy: 96.3%\n",
      "[Batch #: 25600] Avg. Loss: 0.111, Accuracy: 96.8%\n",
      "[Batch #: 32000] Avg. Loss: 0.109, Accuracy: 96.8%\n",
      "[Batch #: 38400] Avg. Loss: 0.112, Accuracy: 96.8%\n",
      "[Batch #: 44800] Avg. Loss: 0.113, Accuracy: 96.5%\n",
      "[Batch #: 51200] Avg. Loss: 0.100, Accuracy: 96.8%\n",
      "[Batch #: 57600] Avg. Loss: 0.102, Accuracy: 97.0%\n",
      "\n",
      "Epoch: 3\n",
      "[Batch #: 6400] Avg. Loss: 0.071, Accuracy: 97.8%\n",
      "[Batch #: 12800] Avg. Loss: 0.077, Accuracy: 97.8%\n",
      "[Batch #: 19200] Avg. Loss: 0.086, Accuracy: 97.3%\n",
      "[Batch #: 25600] Avg. Loss: 0.076, Accuracy: 97.6%\n",
      "[Batch #: 32000] Avg. Loss: 0.080, Accuracy: 97.6%\n",
      "[Batch #: 38400] Avg. Loss: 0.069, Accuracy: 97.8%\n",
      "[Batch #: 44800] Avg. Loss: 0.070, Accuracy: 98.0%\n",
      "[Batch #: 51200] Avg. Loss: 0.082, Accuracy: 97.4%\n",
      "[Batch #: 57600] Avg. Loss: 0.072, Accuracy: 97.9%\n",
      "\n",
      "Epoch: 4\n",
      "[Batch #: 6400] Avg. Loss: 0.059, Accuracy: 98.0%\n",
      "[Batch #: 12800] Avg. Loss: 0.053, Accuracy: 98.5%\n",
      "[Batch #: 19200] Avg. Loss: 0.062, Accuracy: 98.0%\n",
      "[Batch #: 25600] Avg. Loss: 0.049, Accuracy: 98.4%\n",
      "[Batch #: 32000] Avg. Loss: 0.054, Accuracy: 98.3%\n",
      "[Batch #: 38400] Avg. Loss: 0.048, Accuracy: 98.4%\n",
      "[Batch #: 44800] Avg. Loss: 0.061, Accuracy: 97.9%\n",
      "[Batch #: 51200] Avg. Loss: 0.069, Accuracy: 97.7%\n",
      "[Batch #: 57600] Avg. Loss: 0.061, Accuracy: 98.1%\n",
      "\n",
      "Epoch: 5\n",
      "[Batch #: 6400] Avg. Loss: 0.046, Accuracy: 98.7%\n",
      "[Batch #: 12800] Avg. Loss: 0.036, Accuracy: 98.7%\n",
      "[Batch #: 19200] Avg. Loss: 0.038, Accuracy: 98.8%\n",
      "[Batch #: 25600] Avg. Loss: 0.037, Accuracy: 98.8%\n",
      "[Batch #: 32000] Avg. Loss: 0.046, Accuracy: 98.5%\n",
      "[Batch #: 38400] Avg. Loss: 0.052, Accuracy: 98.4%\n",
      "[Batch #: 44800] Avg. Loss: 0.052, Accuracy: 98.2%\n",
      "[Batch #: 51200] Avg. Loss: 0.048, Accuracy: 98.4%\n",
      "[Batch #: 57600] Avg. Loss: 0.052, Accuracy: 98.3%\n",
      "\n",
      "Epoch: 6\n",
      "[Batch #: 6400] Avg. Loss: 0.033, Accuracy: 99.1%\n",
      "[Batch #: 12800] Avg. Loss: 0.043, Accuracy: 98.6%\n",
      "[Batch #: 19200] Avg. Loss: 0.034, Accuracy: 98.9%\n",
      "[Batch #: 25600] Avg. Loss: 0.045, Accuracy: 98.6%\n",
      "[Batch #: 32000] Avg. Loss: 0.042, Accuracy: 98.6%\n",
      "[Batch #: 38400] Avg. Loss: 0.034, Accuracy: 98.9%\n",
      "[Batch #: 44800] Avg. Loss: 0.044, Accuracy: 98.5%\n",
      "[Batch #: 51200] Avg. Loss: 0.038, Accuracy: 98.7%\n",
      "[Batch #: 57600] Avg. Loss: 0.034, Accuracy: 99.0%\n",
      "\n",
      "Epoch: 7\n",
      "[Batch #: 6400] Avg. Loss: 0.024, Accuracy: 99.3%\n",
      "[Batch #: 12800] Avg. Loss: 0.029, Accuracy: 99.0%\n",
      "[Batch #: 19200] Avg. Loss: 0.030, Accuracy: 99.0%\n",
      "[Batch #: 25600] Avg. Loss: 0.032, Accuracy: 99.0%\n",
      "[Batch #: 32000] Avg. Loss: 0.035, Accuracy: 98.9%\n",
      "[Batch #: 38400] Avg. Loss: 0.028, Accuracy: 99.2%\n",
      "[Batch #: 44800] Avg. Loss: 0.031, Accuracy: 98.9%\n",
      "[Batch #: 51200] Avg. Loss: 0.033, Accuracy: 98.8%\n",
      "[Batch #: 57600] Avg. Loss: 0.034, Accuracy: 98.9%\n",
      "\n",
      "Epoch: 8\n",
      "[Batch #: 6400] Avg. Loss: 0.025, Accuracy: 99.1%\n",
      "[Batch #: 12800] Avg. Loss: 0.019, Accuracy: 99.4%\n",
      "[Batch #: 19200] Avg. Loss: 0.023, Accuracy: 99.3%\n",
      "[Batch #: 25600] Avg. Loss: 0.023, Accuracy: 99.3%\n",
      "[Batch #: 32000] Avg. Loss: 0.026, Accuracy: 99.2%\n",
      "[Batch #: 38400] Avg. Loss: 0.032, Accuracy: 98.9%\n",
      "[Batch #: 44800] Avg. Loss: 0.029, Accuracy: 99.1%\n",
      "[Batch #: 51200] Avg. Loss: 0.032, Accuracy: 98.8%\n",
      "[Batch #: 57600] Avg. Loss: 0.031, Accuracy: 99.1%\n",
      "\n",
      "Epoch: 9\n",
      "[Batch #: 6400] Avg. Loss: 0.019, Accuracy: 99.4%\n",
      "[Batch #: 12800] Avg. Loss: 0.015, Accuracy: 99.6%\n",
      "[Batch #: 19200] Avg. Loss: 0.015, Accuracy: 99.5%\n",
      "[Batch #: 25600] Avg. Loss: 0.020, Accuracy: 99.4%\n",
      "[Batch #: 32000] Avg. Loss: 0.023, Accuracy: 99.3%\n",
      "[Batch #: 38400] Avg. Loss: 0.021, Accuracy: 99.2%\n",
      "[Batch #: 44800] Avg. Loss: 0.028, Accuracy: 98.9%\n",
      "[Batch #: 51200] Avg. Loss: 0.023, Accuracy: 99.3%\n",
      "[Batch #: 57600] Avg. Loss: 0.032, Accuracy: 98.7%\n",
      "\n",
      "Epoch: 10\n",
      "[Batch #: 6400] Avg. Loss: 0.019, Accuracy: 99.4%\n",
      "[Batch #: 12800] Avg. Loss: 0.014, Accuracy: 99.6%\n",
      "[Batch #: 19200] Avg. Loss: 0.011, Accuracy: 99.8%\n",
      "[Batch #: 25600] Avg. Loss: 0.021, Accuracy: 99.2%\n",
      "[Batch #: 32000] Avg. Loss: 0.019, Accuracy: 99.3%\n",
      "[Batch #: 38400] Avg. Loss: 0.021, Accuracy: 99.3%\n",
      "[Batch #: 44800] Avg. Loss: 0.027, Accuracy: 99.0%\n",
      "[Batch #: 51200] Avg. Loss: 0.025, Accuracy: 99.1%\n",
      "[Batch #: 57600] Avg. Loss: 0.022, Accuracy: 99.2%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch: {epoch + 1}\")\n",
    "    train_epoch(model, train_loader, loss_function, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f38e6-f372-4540-ad34-794996af8a76",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0c95bc0-c519-426c-bcd2-3fa30d046987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates a trained model's prediction nperformance against a data loader and device\n",
    "    \"\"\"\n",
    "    model.eval()                                 # Sets model's gradient mode\n",
    "    true_predictions = 0\n",
    "    sample_count = 0\n",
    "    \n",
    "    with torch.no_grad():                        # Disables gradient tracking        \n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted_class = torch.max(outputs, 1) # Gets the class with highest score\n",
    "            sample_count += targets.size(0)\n",
    "            true_predictions += (predicted_class == targets).sum().item()\n",
    "\n",
    "    return 100.0 * true_predictions/sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95565011-7963-4de3-87ea-90aec1b3326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.72%\n"
     ]
    }
   ],
   "source": [
    "# Calculates the accuracy on the test dataset\n",
    "accuracy = evaluate(model, test_loader, device)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
