{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de792da5",
   "metadata": {},
   "source": [
    "# Exercises on Data Pipeline in PyTorch\n",
    "\n",
    "In this excercise, you will build a data pipeline for a pet breed classification task using [_Oxford-IIIT Pet Dataset_](https://www.robots.ox.ac.uk/~vgg/data/pets/) to gain skill to handle complex data scenarios. You will learn how build a robust and efficient data pipeline that can handle data accessibility and quality issues to make model more reliable by adding data augmentation and error handling to avoid training crash due to just one bad image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec997d8",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a8891",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "\n",
    "_Oxford-IIIT Pet Dataset_ is a 37 category (25 breeds for cats and 12 breeds for dogs) pet dataset (~800 MB) with roughly 200 images for each class. The images have a large variations in scale, pose and lighting. All images have an associated ground truth annotation of breed, head ROI, and pixel level trimap segmentation. To keep things simple, you should just be using breed label from the ground truth data. After downloading and unzipping the dataset file, there will be a folder full of JPEG images generically named like <breed_name>_1.jpg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a709ef6",
   "metadata": {},
   "source": [
    "**Downloading Data Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fd134",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\"\n",
    "annotations_url = \"https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz\"\n",
    "\n",
    "# Creates dataset directory, if does not exist\n",
    "dataset_folder = \"./datasets/oxford-iiit-pet\"\n",
    "...\n",
    "\n",
    "# Downloads image file only if it does not exist\n",
    "...\n",
    "\n",
    "# Downloads annotations file only if it does not exist\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c837d6",
   "metadata": {},
   "source": [
    "**Decompressing Data Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a99814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompresses images file\n",
    "...\n",
    "\n",
    "# Decompress annotations file\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0803cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads class-id (labels) from list.txt from folder 'annotations'\n",
    "# Note: Open list.txt to understand the format. In addition to class-id, it also contains information\n",
    "# on the speecies (cat or dog) and breed (e.g. Abyssinian, Bengal, etc.). To make things simple, you should\n",
    "# just be using class-id [1 through 37] as labels for model to predict.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf77c9f",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e57b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots few of the random images in a figure to visualize them\n",
    "# (Visualizes those samples images in a grid format)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5715f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sizes of sample images to confirm that the image sizes varies\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3fc4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer any one sample image and checks for min. and max. pixel values for each channel\n",
    "# This will be used later for normalization step.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33972fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the minimum and maximum class-id values\n",
    "# This is required to confirm if class-ids are required to be shifted to start from 0\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3aa1d",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Handling image augmentation (only for training), resizing, format conversion, and normalization using PyTorch's transformation pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986b8799",
   "metadata": {},
   "source": [
    "**Image Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose transformations for \n",
    "# 1) resizing,\n",
    "# 2) centering cropping and\n",
    "# 3) normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ee329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, compose transformations for training set with data augmentation\n",
    "# in addition to above three transformations to be applied on validation/test set\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3349f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the above composed transformations to sample images and checks if all \n",
    "# the transformations are actually applied on those images\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d905d668",
   "metadata": {},
   "source": [
    "**Building Data Pipeline**\n",
    "\n",
    "Build data pipeline to\n",
    "- access images files and pairing them with their labels (class-ids),\n",
    "- get the images into the right format, correct size, data type, and structure for model to actually learn from them, and finally to\n",
    "- load data in batches for efficient learning.\n",
    "\n",
    "Use PyTorch's `Dataset` and `DataLoader` classes as primary tools to this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a custom `Dataset` class for Oxford-IIIT Pet dataset for PyTorch to handle the data, as required\n",
    "\n",
    "class OxfordPetDataset(Dataset):\n",
    "    \"\"\"Represents Oxford-IIIT Pet Dataset that follows lazy loading pattern.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = ...\n",
    "        self.images_dir = ...\n",
    "        self.transform = ...\n",
    "\n",
    "        # Prepare a list of path for all images (for Dataset to load the images later on-the-fly)\n",
    "        ...\n",
    "\n",
    "        # Loads labels from .mat file\n",
    "        # (Also, ensure adjusting labels to start from 0)\n",
    "        ...\n",
    "\n",
    "        # A list to hold statistics on the individual images being accessed\n",
    "        ...\n",
    "\n",
    "        # A list to keep track of error during transformations\n",
    "        ...\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        ...\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Retrieves the image and label at the specified index.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Prepare the image file name based on the index\n",
    "            ...\n",
    "\n",
    "            # Load image from disk\n",
    "            ...\n",
    "\n",
    "            # Checks the file for corruption (integrity check)\n",
    "            # (You might need to re-open the image as it might get closed during integrity check)\n",
    "            ...\n",
    "\n",
    "            # Skips smaller images (as it may break transformation)\n",
    "            ...\n",
    "\n",
    "            # Converts gray-scale images to RGB\n",
    "            ...\n",
    "\n",
    "            # Applies transformations if any\n",
    "            ...\n",
    "\n",
    "            # Records statistics on the image\n",
    "            ...\n",
    "\n",
    "            # Return the image and label\n",
    "            ...\n",
    "\n",
    "        except Exception as e:\n",
    "            # Logs the error\n",
    "            ...\n",
    "            # Print the error message\n",
    "            ...\n",
    "            # Keeps pipeline moving even when files are broken\n",
    "\n",
    "    def get_error_summary(self):\n",
    "        \"\"\"Provides error summary to inspect which images had problems during loading or transformation.\"\"\"\n",
    "\n",
    "        # Show errors only for first images if the list is too long\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76bd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the instance of the custom Dataset class for training and validation sets\n",
    "dataset = OxfordPetDataset(\n",
    "    root_dir=...,\n",
    "    transform=...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2405eb",
   "metadata": {},
   "source": [
    "**Splitting Data**\n",
    "\n",
    "Split the the full dataset into training, validation and test set.\n",
    "\n",
    "You will use the train set to train the model, validation set to check the model's performance during training and to tune the model paraneters, and test set for the final check on the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splits the full dataset into train, validation and test set with 70:15:15 ratio.\n",
    "\n",
    "train_set, val_set, test_set = ...\n",
    "\n",
    "# Print the length of each of splitted dataset\n",
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f5a08",
   "metadata": {},
   "source": [
    "**Batching Data**\n",
    "\n",
    "Use `DataLoader` to load the data efficiently in batches. You may consider 32 or 64 samples in a batch. Shuffle the samples only in train set as shuffling samples in validation and test set does not make sense as these are used for model evaluation and not for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1daec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataLoaders for each set of the data\n",
    "train_set_loader = DataLoader(\n",
    "    dataset = ..., \n",
    "    batch_size = ..., \n",
    "    shuffle = ...\n",
    ")\n",
    "\n",
    "val_set_loader = DataLoader(\n",
    "    dataset = ..., \n",
    "    batch_size = ..., \n",
    "    shuffle = ...\n",
    ")\n",
    "\n",
    "test_set_loader = DataLoader(\n",
    "    dataset = ..., \n",
    "    batch_size = ..., \n",
    "    shuffle = ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a test run to ensure DataLoader is working as expected\n",
    "# by fetching a single batch from training set and printing the batch shapes for images and its labels.\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
